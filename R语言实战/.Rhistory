win.graph(width = 4.8,  height = 2.5, pointsize = 8)
plot(wages, ylab = "Monthly Wages", xlab = "Time", type = "l").
lines(as.vector(xfit), as.vector(yfit_2), col = "red")
data("tempdub")
temper_month <- season(tempdub)
lm_temper_1 <- lm(tempdub ~ temper_month - 1)#减一意味着不包含截距项
summary(lm_temper_1)
lm_temper_2 <- lm(tempdub ~ temper_month)
summary(lm_temper_2)#虽然这是两种不同的回归结果，但是表达的情况一样
har_temper <- harmonic(tempdub,1)#将这里的气温转换为cos和 sin 的n阶矩阵
lm_temper_3 <- lm(tempdub ~har_temper)
summary(lm_temper_3)
# load packages
library(dplyr)
library(nycflights13)
# print the flights dataset from nycflights13
flights
# besides just using select() to pick columns...
flights %>% select(carrier, flight)
# ...you can use the minus sign to hide columns
flights %>% select(-month, -day)
install.packages("tinytex")
example_text00 = c("23333|RR|PP", "35555|CCCC", "bearclub|2017")
unlist(strsplit(example_text1, "|"))
unlist(strsplit(example_text00, "|"))
# 以#进行字符串切分
unlist(strsplit(example_text1, "#"))
# 基础字符处理函数的正则表达式应用
example_text1 = c("23333#RRR#PP", "35555#CCCC", "bearclub#2017")
# 以#进行字符串切分
unlist(strsplit(example_text1, "#"))
##  [1] "23333"    "RRR"      "PP"       "35555"    "CCCC"     "bearclub"
##  [7] "2017"
# 以空字符集进行字符串切分
unlist(strsplit(example_text1, "\\s"))
unlist(strsplit(example_text00, "|"))
example_text00
unlist(strsplit(example_text00, "|"))
str_view(x, "|?")
library(stringr)
str_view(example_text00, "|")
str_view(example_text00, "*|*")
str_view(example_text00, "|*")
str_view(example_text00, "|+")
str_view(example_text00, ".|.")
View(har_temper)
rm(list = ls)
rm(list = ls())
## 抓取某网页二手房数据 ##
# 加载所需的包
library("xml2")
library("rvest")
library("dplyr")
library("stringr")
# 对爬取页数进行设定并创建数据框
i = 1:100
house_inf = data.frame()
# 利用for循环封装爬虫代码，进行批量抓取
for (i in 1:100) {
# 发现url规律，利用字符串函数进行url拼接并规定编码
web = read_html(str_c("http://hz.lianjia.com/ershoufang/pg", i), encoding = "UTF-8")
# 提取房名信息
house_name = web %>% html_nodes(".houseInfo a") %>% html_text()
# 提取房名基本信息并消除空格
house_basic_inf = web %>% html_nodes(".houseInfo") %>% html_text()
house_basic_inf = str_replace_all(house_basic_inf, " ", "")
# 提取二手房地址信息
house_address = web %>% html_nodes(".positionInfo a") %>% html_text()
# 提取二手房总价信息
house_totalprice = web %>% html_nodes(".totalPrice") %>% html_text()
# 提取二手房单价信息
house_unitprice = web %>% html_nodes(".unitPrice span") %>% html_text()
# 创建数据框存储以上信息
house_name <- house_address[seq(1,59,2)]
house_address <- house_address[seq(2,60,2)]
house = data.frame(house_name, house_basic_inf, house_address, house_totalprice, house_unitprice)
house_inf = rbind(house_inf, house)
}
View(house_inf)
# 利用for循环封装爬虫代码，进行批量抓取
for (i in 1:100) {
# 发现url规律，利用字符串函数进行url拼接并规定编码
web = read_html(str_c("http://hz.lianjia.com/ershoufang/pg", i), encoding = "UTF-8")
# 提取房名信息
house_name = web %>% html_nodes(".houseInfo a") %>% html_text()
# 提取房名基本信息并消除空格
house_basic_inf = web %>% html_nodes(".houseInfo") %>% html_text()
house_basic_inf = str_replace_all(house_basic_inf, " ", "")
# 提取二手房地址信息
house_address = web %>% html_nodes(".positionInfo a") %>% html_text()
# 提取二手房总价信息
house_totalprice = web %>% html_nodes(".totalPrice") %>% html_text()
# 提取二手房单价信息
house_unitprice = web %>% html_nodes(".unitPrice span") %>% html_text()
# 创建数据框存储以上信息
house_name <- house_address[seq(1,59,2)]
house_address <- house_address[seq(2,60,2)]
house = data.frame(house_name, house_basic_inf, house_address, house_totalprice, house_unitprice)
house_inf = rbind(house_inf, house)
}
View(house_inf)
# 利用for循环封装爬虫代码，进行批量抓取
for (i in 1:100) {
# 发现url规律，利用字符串函数进行url拼接并规定编码
web = read_html(str_c("http://hz.lianjia.com/ershoufang/pg", i), encoding = "UTF-8")
# 提取房名信息
house_name = web %>% html_nodes(".houseInfo a") %>% html_text()
# 提取房名基本信息并消除空格
house_basic_inf = web %>% html_nodes(".houseInfo") %>% html_text()
house_basic_inf = str_replace_all(house_basic_inf, " ", "")
# 提取二手房地址信息
house_address = web %>% html_nodes(".positionInfo a") %>% html_text()
# 提取二手房总价信息
house_totalprice = web %>% html_nodes(".totalPrice") %>% html_text()
# 提取二手房单价信息
house_unitprice = web %>% html_nodes(".unitPrice span") %>% html_text()
# 创建数据框存储以上信息
house_name <- house_address[seq(1,59,2)]
house_address <- house_address[seq(2,60,2)]
house = data.frame(house_name, house_basic_inf, house_address, house_totalprice, house_unitprice)
house_inf = rbind(house_inf, house)
}
View(house_inf)
install.packages("httr")
install.packages("httr")
# install.packages("httr")
library(httr)
cookie = ""
headers = c('Accept' = 'application/json',
'User-Agent' = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.117 Safari/537.36',
'Referer' = 'http://study.163.com/courses',
'edu-script-token' = '1c1f84a1b85a48aba8a4d440552f5f69',
'Connection' = 'keep-alive',
'Cookie' = cookie)
# 构造参数信息
payload = list('pageIndex' = 1, 'pageSize' = 50, 'relativeOffset' = 0,'frontCatgoryId' = '-1')
# 二次请求的实际url
url = "http://study.163.com/p/search/studycourse.json"
# POST方法执行单词请求
result = POST(url, add_headers(.headers = headers), body = payload, encode = "json")
result
choose(3,2)
permutation(3,2)
write.csv(house_inf, file = "C:/Users/terry/Documents/我爱学习/统计软件/R/R脚本/R语言实战/house_inf.csv")
rm(list = ls())
?grep
# switch(expr,list)
switch(2,mean(1:10),1:4,1:10)
# switch(expr,list)
switch(2,mean(1:10),1:5,1:10)
source('~/.active-rstudio-document')
switch (y,
fruit = "apple",
vegetable = "brocoli",
meat = "beef"
)
?cat
?print
# for(i in seq){expr}
#print 函数无法打印多个对象，所以在这里使用cat函数
n <- c(2,5,10)
for(i in n){
x <- sqrt(i)
cat("sqrt(",i,"):",x,"\n")#\n的正则表达式为回车
}
print(x)
for(i in n){
print(x)
}
for(i in 1:10){print(i)}
#while循环
# while(condition){expr}
x <- c(1,1)#生成10个斐波那契数列，这个c(1,1)为数列的两个初始值
i <- 3
while(i <= 10){
x[i] <- x[i-1] + x[i-2]
i <- i + 1
}
x
repeat{
if(i>length(pv))break
if(pv[i]<=5) results[i] <- "初级用户" else
if(pv[i]<=15) results[i] <- "中级用户" else
results[i] <- "高级用户"
i <- i+1
}
#repeat-break 循环
#repeat 是无限循环语句
#直到达到循环条件时，使用break 语句直接跳出循环
# repeat expr 或 repeat{if(condition){break}}
pv <- c(1,1,2,3,1,1,15,7,18)
i <- 1
results <- ""#空的字符串
repeat{
if(i>length(pv))break
if(pv[i]<=5) results[i] <- "初级用户" else
if(pv[i]<=15) results[i] <- "中级用户" else
results[i] <- "高级用户"
i <- i+1
}
results
?stop
std2 <- function(x){
if(!is.numeric(x)){
stop("wrong input \n")
}
if(length(x)==1){
stop("cannot complete calculation \n")
}
result <- sqrt(sum((x-mean(x))^2/(length(x)-1)))
return(result)
}
std2(x)
std2(c(1:3))
std2(3)
std2 <- function(x){
if(!is.numeric(x)){
stop("wrong input \n")
}
if(length(x)==1){
stop("cannot complete calculation \n")
}
result <- sqrt((sum(x-mean(x))^2)/(length(x)-1))
return(result)
}
std2(x)
#编写函数
mystats <- function(x, parametric = TRUE, print = FALSE){
if(parametric){#若果parametric为TRUE
center <- mean(x)
spread <- sd(x)
}else{#如果parametric为FALSE
center <- median(x)
spread <- mad(x)
}
if(print & parametric){#如果两个皆为TRUE
cat("Mean = ", center, "\n", "SD = ", spread, "\n")
}else if(print & !parametric){#如果print为TRUE但是它不是parametric的选项的话
cat("Median = ", center, "\n", "MAD = ", spread, "\n")
}
result <- list(center = center, spread = spread)
return(result)
}
#首先要生成一些服从于正态分布的数据
set.seed(1234)
x <- rnorm(500)
y <- mystats(x)
y <- mystats(x, parametric = FALSE, print = TRUE)
y
View(house_inf)
house_inf2 <- house_inf %>%
separate(house_basic_inf,c('室和厅的数量',
'平米',
'方位',
'装修程度',
'所在楼层',
'房屋种类'),
sep = "_")
library(tidyverse) #加载包
house_inf2 <- house_inf %>%
separate(house_basic_inf,c('室和厅的数量',
'平米',
'方位',
'装修程度',
'所在楼层',
'房屋种类'),
sep = "_")
View(house_inf2)
setwd("C:/Users/terry/Documents/我爱学习/统计软件/R/R脚本/R语言实战")
house_inf <- read.csv("house_inf.csv",stringsAsFactors = FALSE, encoding = "UTF-8")
house_inf2 <- house_inf %>%
separate(house_basic_inf,c('室和厅的数量',
'平米',
'方位',
'装修程度',
'所在楼层',
'房屋种类'),
sep = "_")
View(house_inf2)
str_extract_all(house_inf$house_totalprice, "[0-9]+")
x <- c("<title>HTML 教程</title>", "Nanjing 210000",
"Nanjing University of Finance & Economics, 210023",
"<div id=\"navfirst\">
<ul id=\"menu\">
<li id=\"h\"><a href=\"/h.asp\" title=\"HTML 系列教程\">HTML 系列教程</a></li>
<li id=\"b\"><a href=\"/b.asp\" title=\"浏览器脚本教程\">浏览器脚本</a></li>
<li id=\"s\"><a href=\"/s.asp\" title=\"服务器脚本教程\">服务器脚本</a></li>
<li id=\"d\"><a href=\"/d.asp\" title=\"ASP.NET 教程\">ASP.NET 教程</a></li>
<li id=\"x\"><a href=\"/x.asp\" title=\"XML 系列教程\">XML 系列教程</a></li>
<li id=\"ws\"><a href=\"/ws.asp\" title=\"Web Services 系列教程\">Web Services
系
列教程</a></li>
<li id=\"w\"><a href=\"/w.asp\" title=\"建站手册\">建站手册</a></li>
</ul>
</div>")
# 匹配<title>里的内容
(t1 = str_extract_all(x, "<title>.*</title>"))
## [1] "<title>HTML 教程</title>"
##
## [[2]]
## character(0)
##
## [[3]]
## character(0)
##
## [[4]]
## character(0)
gsub("<.+?>", "", t1[[1]])
## [1] "HTML 教程"
# 匹配标签<li>中的内容
(t1 = str_extract_all(x, "<li.*>.*</li>"))
# </a></li>"
# ## [4] "<li id=\"d\"><a href=\"/d.asp\" title=\"ASP.NET 教程\">ASP.NET
# 教程</a></li>"
# ## [5] "<li id=\"x\"><a href=\"/x.asp\" title=\"XML 系列教程\">XML 系列教
# 程</a></li>"
# ## [6] "<li id=\"ws\"><a href=\"/ws.asp\" title=\"Web Services 系列教程
# \">Web Services 系列教程</a></li>"
# ## [7] "<li id=\"w\"><a href=\"/w.asp\" title=\"建站手册\">建站手册
# </a></li>"
# # 匹配超级链接标签<a>中的内容
(t1 = str_extract_all(x, "<a.*>.*</a>"))
(t1 = t1[[4]])
# 匹配所有数字
str_extract_all(x, "[0-9]+")
str_extract_all(x, "[:digit:]+")
?str_extract
library(rvest)
library(stringr)
# 豆瓣排名前25电影及评价爬取
url <-'http://movie.douban.com/top250?format=text'
webpage <- read_html(url)
# 1， 获取排名
# 用CSS选择器获取排名部分【关键是这句话】
rank_data_html <- html_nodes(webpage,'.pic em') # class 为 pic类的子标签em
# 把排名转换为文本
rank_data <- html_text(rank_data_html)
# 检查一下数据
head(rank_data)
## [1] "1" "2" "3" "4" "5" "6"
# 2， 获取名称
# 用CSS选择器获取标题部分
title_data_html <- html_nodes(webpage,'.info .hd a')
title_data_html <- html_node(title_data_html,'.title')
# 爬虫综合实践
# 三、设计R语言程序
# 把排名转换为文本，并提取第一个“/”左侧部分
title_data <- html_text(title_data_html) %>% # 去掉HTML标记
str_trim # 去掉字符串头和尾部的空格
# 检查一下数据
head(title_data)
## [1] "肖申克的救赎" "霸王别姬" "这个杀手不太冷" "阿甘正传"
## [5] "美丽人生" "泰坦尼克号"
# 3， 获取上映年份
year_data_html <- html_nodes(webpage,'.info .bd p') # 获取子代码块
year_data <- html_text(year_data_html) %>% # 去掉HTML标记
str_extract("[0-9]{4}.{1}\\/") %>% # 提取 数值 加 空格 加 斜杠的
部分
str_extract("[0-9]{4}") %>% # 提取数值部分
na.omit() %>% # 去掉缺失的元素
as.numeric() # 转为数值类型
## [1] "肖申克的救赎" "霸王别姬" "这个杀手不太冷" "阿甘正传"
## [5] "美丽人生" "泰坦尼克号"
# 3， 获取上映年份
year_data_html <- html_nodes(webpage,'.info .bd p') # 获取子代码块
year_data <- html_text(year_data_html) %>% # 去掉HTML标记
str_extract("[0-9]{4}.{1}\\/") %>% # 提取 数值 加 空格 加 斜杠的部分
str_extract("[0-9]{4}") %>% # 提取数值部分
na.omit() %>% # 去掉缺失的元素
as.numeric() # 转为数值类型
year_data
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,pattern = '<span>[:digit:]+人评价</span>')
Rating.num_line <- unlist(Rating)
Rating.num <- str_extract(Rating.num_line, pattern = "[:digit:]+") %>%
as.numeric()
Rating.num # 检查结果
## [1] 1116962 815015 1035401 882652 515091 821022 821626 466127
## [9] 909701 599642 577582 817720 690299 554332 608895 584045
## [17] 411845 506965 606484 337492 495287 442243 316873 652575
## [25] 695467
# 5， 获取评分
# 用CSS选择器获取评分部分【关键是这句话】
Score_html <- html_nodes(webpage,'.rating_num')
Score <- html_text(Score_html) %>% as.numeric()
# 数据合并
MovieData <- data.frame(MovieName = title_data, RatingNum = Rating.num,
Score = Score, Rank = rank_data,
year = year_data,
stringsAsFactors = FALSE)
# 数据合并
MovieData <- data.frame(MovieName = title_data,
Score = Score, Rank = rank_data,
year = year_data,
stringsAsFactors = FALSE)
View(MovieData)
# 设定网址链接
urli = paste0("https://movie.douban.com/top250?start=", (0:9)*25 )
(0:9)*25
# 分别读取信息
tempi = list()
for(i in 1:length(urli)){
tempi[[i]] = getData(urli[i])
}
# 合并为一个数据框
for(i in 1:length(urli)){
if(i==1){
MovieData250 = tempi[[i]]
}else{
MovieData250 = rbind(MovieData250, tempi[[i]])
}
}
# 检查
head(MovieData250)
Rating.num <- str_extract(Rating.num_line, pattern = "[:digit:]+") %>%as.numeric()
Rating.num # 检查结果
Rating.num_line
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,pattern = '<span>[:digit:]+人评价</span>')
Rating
View(webpage)
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,pattern = '<span>[:digit:]人评价</span>')
View(Rating)
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,pattern = '<span>[:digit:]+人评价</span>')
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,pattern = '<span>[:digit:].人评价</span>')
Rating.num_line <- unlist(Rating)
library(tidyverse) #加载包
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,pattern = "<span>[:digit:]+人评价</span>")
View(Rating)
grep("<span>[:digit:]+人评价</span>",webpage)
grep(pattern = "<span>[:digit:]+人评价</span>",data = webpage)
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,pattern = "<span>[:digit:]+人评价</span>",perl = TRUE)
?str_extract_all
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,pattern = "<span>[:digit:]+人评价</span>")
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,pattern = "<span>[:digit:]+人评价</span>",simplify = TRUE)
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,pattern = "<span>[:digit:]+人评价</span>",simplify = FALSE)
str_view(webpage, "<span>[:digit:]+人评价</span>")
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,
pattern = "<span>[:digit:]*人评价</span>",
simplify = FALSE)
## [1] 1994 1993 1994 1994 1997 1997 2001 1993 2010 2008 2009 2009 1998 2004
## [15] 1995 1998 1972 1988 2014 2011 2002 2011 1939 2006 2010
# 爬虫综合实践
# 三、设计R语言程序
# 4, 获取评论人数
Rating <- str_extract_all(webpage,
pattern = "<span>[:digit:]*人评价</span>",
simplify = TRUE)
View(Rating)
grep("<span>[:digit:]*人评价</span>",webpage)
grep("a.+b", c("ab","a b","A b","a#b","a##b"))
grep("a.?b", c("ab","a b","A b","a##b"))
#
grep("a.{1,3}b",c("ab","a b","A b","a##b"))
#
grep("a.{2,3}b", c("ab","a b","A b","a##b"))
#
grep("a.{2}b", c("ab","a b","A b","a##b"))
grep("a.{3}b", c("ab","a b","A b","a##b"))
